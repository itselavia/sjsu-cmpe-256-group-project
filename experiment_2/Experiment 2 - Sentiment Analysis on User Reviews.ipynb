{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Clean the Reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_review_data():\n",
    "\n",
    "    with open(\"/Users/akshay/Downloads/australian_user_reviews.json\", \"r\") as raw_input:\n",
    "        with open(\"/Users/akshay/Downloads/australian_user_reviews_cleaned.json\", \"w\") as cleaned_file:\n",
    "            try:\n",
    "                for line in raw_input:\n",
    "                    withoutSingleQuotes = line.replace('\\'', '\\\"')\n",
    "                    withoutSingleQuotes = withoutSingleQuotes.replace(\"True\", \"true\")\n",
    "                    withoutSingleQuotes = withoutSingleQuotes.replace(\"False\", \"false\")\n",
    "                    main_review_indexes = [m.start() for m in re.finditer(\"\\\"review\\\"\", withoutSingleQuotes)]\n",
    "                    for main_review_index in main_review_indexes:\n",
    "                        main_review_index = main_review_index + 11\n",
    "                        current_brace_index = withoutSingleQuotes[main_review_index:].find(\"}\")\n",
    "                        temp = withoutSingleQuotes[main_review_index: main_review_index + current_brace_index - 1]\n",
    "                        repeatingDoubleQuotesIndexes = [m.start() for m in re.finditer(\"\\\"\", temp)]\n",
    "                        for i in repeatingDoubleQuotesIndexes:\n",
    "                            toReplaceIndex = main_review_index + i\n",
    "                            withoutSingleQuotes = withoutSingleQuotes[:toReplaceIndex] + \"'\" + withoutSingleQuotes[toReplaceIndex + 1:]\n",
    "                    withoutSingleQuotes = withoutSingleQuotes.replace(\"\\\\\", \"\")\n",
    "                    cleaned_file.write(withoutSingleQuotes)\n",
    "            except:\n",
    "                pass\n",
    "if __name__ == \"__main__\":\n",
    "    clean_review_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U spacy\n",
    "\n",
    "# Download spacy's pretrained statistical models for English language\n",
    "# We are downloading the \"en_core_web_lg\", which is English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl\n",
    "# The size of this download pretrained models is 746MB. The word vectors included in this model has 685k keys, 685k unique vectors (300 dimensions)\n",
    "\n",
    "#!python3 -m spacy download en\n",
    "#!python3 -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate the formatted training dataset from raw data\n",
    "\n",
    "From the cleaned reviews data, generate training data in the following format:\n",
    "\n",
    "|review_text                                | sentiment \t|\n",
    "|-----------------------------------------\t|-----------\t|\n",
    "|I liked this game                       \t| 1         \t|\n",
    "|I found the game a little underwhelming \t| 0         \t|\n",
    "|the best sequel to the Star Wars game!  \t| 1         \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def generate_test_data():\n",
    "    resultRows = []\n",
    "    with open(\"/Users/akshay/Downloads/australian_user_reviews_cleaned.json\", \"r\") as cleaned_file:\n",
    "        for line in cleaned_file:\n",
    "            try:\n",
    "                json_obj = json.loads(line)\n",
    "                reviews = json_obj[\"reviews\"]\n",
    "                for review in reviews:\n",
    "                    review_text = review[\"review\"]\n",
    "                    sentiment = review[\"recommend\"]\n",
    "                    resultRows.append([review_text, sentiment])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                    \n",
    "    with open(\"/Users/akshay/Downloads/experiment_2_sentiment_dataset.tsv\", \"w\") as sentiment_dataset:\n",
    "        for entry in resultRows:\n",
    "            sentiment_dataset.write(entry[0] + \"\\t\" + str(int(entry[1])) + \"\\n\")\n",
    "                \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple yet with great replayability. In my opi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's unique and worth a playthrough.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great atmosphere. The gunplay can be a bit chu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I know what you think when you see this title ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For a simple (it's actually not all that simpl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  sentiment\n",
       "0  Simple yet with great replayability. In my opi...          1\n",
       "1               It's unique and worth a playthrough.          1\n",
       "2  Great atmosphere. The gunplay can be a bit chu...          1\n",
       "3  I know what you think when you see this title ...          1\n",
       "4  For a simple (it's actually not all that simpl...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "review_df = pd.read_csv(\"/Users/akshay/Downloads/experiment_2_sentiment_dataset.tsv\", sep='\\t', header = None)\n",
    "columns_name = ['review_text', 'sentiment']\n",
    "review_df.columns = columns_name\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59278, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    52449\n",
       "0     6829\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create the NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_tokenizer(review):\n",
    "    review = str(review)\n",
    "    document = nlp(review)\n",
    "    \n",
    "    # Collect all the token from the review text. Need extra check for pronouns\n",
    "    tokens = []\n",
    "    for token in document:\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            doc_tokens = token.lemma_.lower().strip()\n",
    "        else:\n",
    "            doc_tokens = token.lower_\n",
    "        tokens.append(doc_tokens)\n",
    "    \n",
    "    # Remove tokens which are stopwords or punctuation\n",
    "    punctuation = string.punctuation\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords and token not in punctuation:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_tokenizer(\"Simple yet with great replayability. In my opinion does 'zombie' hordes and team work better than left 4 dead plus has a global leveling system. Alot of down to earth 'zombie' splattering fun for the whole family. Amazed this sort of FPS is so rare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer = review_tokenizer)\n",
    "classifier = LinearSVC()\n",
    "sentiment_pipeline = Pipeline([('tfidf', tfidf), ('clf', classifier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(tokenizer=<function review_tokenizer at 0x15c833160>)),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = review_df.dropna()\n",
    "X = review_df['review_text']\n",
    "y = review_df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 256)\n",
    "sentiment_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sentiment_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.39      0.49      1392\n",
      "           1       0.92      0.97      0.95     10458\n",
      "\n",
      "    accuracy                           0.91     11850\n",
      "   macro avg       0.80      0.68      0.72     11850\n",
      "weighted avg       0.89      0.91      0.89     11850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  541,   851],\n",
       "       [  262, 10196]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
